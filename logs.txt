
Starting script iteration 1 at: 2023-11-18 17:18:38

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.437(+0.000), val loss: 10.439(+0.000)

step: 100, train loss: 2.461(-7.976), val loss: 2.508(-7.931)

step: 200, train loss: 2.319(-0.142), val loss: 2.436(-0.072)

step: 300, train loss: 2.305(-0.014), val loss: 2.354(-0.083)

step: 400, train loss: 2.293(-0.012), val loss: 2.264(-0.090)

step: 500, train loss: 2.336(+0.043), val loss: 2.259(-0.005)

step: 600, train loss: 2.225(-0.111), val loss: 2.287(+0.029)

step: 700, train loss: 2.195(-0.031), val loss: 2.175(-0.112)

step: 800, train loss: 2.176(-0.019), val loss: 2.190(+0.015)

step: 900, train loss: 2.113(-0.063), val loss: 2.078(-0.112)

step: 1000, train loss: 2.151(+0.038), val loss: 2.049(-0.029)

step: 1100, train loss: 2.075(-0.077), val loss: 2.088(+0.039)

step: 1200, train loss: 2.012(-0.063), val loss: 2.081(-0.007)

step: 1300, train loss: 2.005(-0.007), val loss: 2.051(-0.031)

step: 1400, train loss: 1.955(-0.050), val loss: 1.977(-0.074)

step: 1500, train loss: 1.954(-0.002), val loss: 1.978(+0.001)

step: 1600, train loss: 1.956(+0.002), val loss: 2.003(+0.026)

step: 1700, train loss: 2.007(+0.051), val loss: 1.947(-0.056)

step: 1800, train loss: 1.968(-0.039), val loss: 1.985(+0.038)

step: 1900, train loss: 1.992(+0.023), val loss: 1.928(-0.057)

Total script runtime: 340.43 seconds

Starting script iteration 2 at: 2023-11-18 17:24:18

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.966(+0.000), val loss: 1.925(+0.000)

step: 100, train loss: 1.923(-0.043), val loss: 1.927(+0.001)

step: 200, train loss: 1.928(+0.005), val loss: 1.968(+0.042)

step: 300, train loss: 1.911(-0.016), val loss: 1.940(-0.028)

step: 400, train loss: 1.920(+0.009), val loss: 1.850(-0.090)

step: 500, train loss: 1.995(+0.075), val loss: 1.949(+0.099)

step: 600, train loss: 1.920(-0.075), val loss: 1.924(-0.024)

step: 700, train loss: 1.927(+0.006), val loss: 1.903(-0.022)

step: 800, train loss: 1.929(+0.003), val loss: 1.899(-0.004)

step: 900, train loss: 1.857(-0.072), val loss: 1.890(-0.009)

step: 1000, train loss: 1.880(+0.023), val loss: 1.932(+0.042)

step: 1100, train loss: 1.959(+0.079), val loss: 1.888(-0.044)

step: 1200, train loss: 1.861(-0.098), val loss: 1.796(-0.093)

step: 1300, train loss: 1.990(+0.129), val loss: 1.931(+0.136)

step: 1400, train loss: 1.883(-0.106), val loss: 1.848(-0.083)

step: 1500, train loss: 1.912(+0.028), val loss: 1.904(+0.056)

step: 1600, train loss: 1.952(+0.040), val loss: 1.928(+0.024)

step: 1700, train loss: 1.900(-0.052), val loss: 1.802(-0.126)

step: 1800, train loss: 1.842(-0.058), val loss: 1.855(+0.052)

step: 1900, train loss: 1.857(+0.014), val loss: 1.900(+0.045)

Total script runtime: 343.91 seconds

Starting script iteration 3 at: 2023-11-18 17:30:02

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.907(+0.000), val loss: 1.959(+0.000)

step: 100, train loss: 1.867(-0.040), val loss: 1.889(-0.071)

step: 200, train loss: 1.821(-0.047), val loss: 1.845(-0.043)

step: 300, train loss: 1.857(+0.037), val loss: 1.844(-0.001)

step: 400, train loss: 1.857(-0.001), val loss: 1.848(+0.004)

step: 500, train loss: 1.845(-0.012), val loss: 1.870(+0.022)

step: 600, train loss: 1.842(-0.003), val loss: 1.842(-0.029)

step: 700, train loss: 1.793(-0.048), val loss: 1.943(+0.101)

step: 800, train loss: 1.838(+0.045), val loss: 1.804(-0.139)

step: 900, train loss: 1.859(+0.020), val loss: 1.896(+0.092)

step: 1000, train loss: 1.873(+0.014), val loss: 1.821(-0.074)

step: 1100, train loss: 1.822(-0.051), val loss: 1.863(+0.042)

step: 1200, train loss: 1.832(+0.010), val loss: 1.861(-0.003)

step: 1300, train loss: 1.807(-0.024), val loss: 1.849(-0.012)

step: 1400, train loss: 1.847(+0.039), val loss: 1.844(-0.005)

step: 1500, train loss: 1.811(-0.035), val loss: 1.788(-0.056)

step: 1600, train loss: 1.853(+0.042), val loss: 1.885(+0.097)

step: 1700, train loss: 1.903(+0.050), val loss: 1.893(+0.008)

step: 1800, train loss: 1.867(-0.035), val loss: 1.835(-0.058)

step: 1900, train loss: 1.795(-0.072), val loss: 1.795(-0.040)

Total script runtime: 341.41 seconds

Starting script iteration 4 at: 2023-11-18 17:35:43

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.838(+0.000), val loss: 1.848(+0.000)

step: 100, train loss: 1.872(+0.034), val loss: 1.828(-0.020)

step: 200, train loss: 1.784(-0.088), val loss: 1.836(+0.008)

step: 300, train loss: 1.824(+0.040), val loss: 1.835(-0.001)

step: 400, train loss: 1.778(-0.045), val loss: 1.878(+0.043)

step: 500, train loss: 1.808(+0.030), val loss: 1.782(-0.096)

step: 600, train loss: 1.790(-0.018), val loss: 1.806(+0.024)

step: 700, train loss: 1.762(-0.028), val loss: 1.808(+0.002)

step: 800, train loss: 1.864(+0.101), val loss: 1.880(+0.073)

step: 900, train loss: 1.783(-0.081), val loss: 1.789(-0.092)

step: 1000, train loss: 1.789(+0.006), val loss: 1.764(-0.025)

step: 1100, train loss: 1.777(-0.012), val loss: 1.824(+0.060)

step: 1200, train loss: 1.830(+0.053), val loss: 1.824(+0.000)

step: 1300, train loss: 1.792(-0.038), val loss: 1.895(+0.071)

step: 1400, train loss: 1.799(+0.007), val loss: 1.791(-0.104)

step: 1500, train loss: 1.764(-0.035), val loss: 1.808(+0.017)

step: 1600, train loss: 1.813(+0.049), val loss: 1.851(+0.043)

step: 1700, train loss: 1.767(-0.046), val loss: 1.737(-0.114)

step: 1800, train loss: 1.790(+0.022), val loss: 1.772(+0.035)

step: 1900, train loss: 1.813(+0.023), val loss: 1.825(+0.053)

Total script runtime: 343.09 seconds

Starting script iteration 5 at: 2023-11-18 17:41:27

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.760(+0.000), val loss: 1.765(+0.000)

step: 100, train loss: 1.777(+0.018), val loss: 1.794(+0.029)

step: 200, train loss: 1.812(+0.035), val loss: 1.768(-0.026)

step: 300, train loss: 1.777(-0.035), val loss: 1.806(+0.038)

step: 400, train loss: 1.746(-0.031), val loss: 1.782(-0.024)

step: 500, train loss: 1.717(-0.029), val loss: 1.761(-0.020)

step: 600, train loss: 1.721(+0.003), val loss: 1.750(-0.011)

step: 700, train loss: 1.766(+0.046), val loss: 1.815(+0.065)

step: 800, train loss: 1.832(+0.066), val loss: 1.860(+0.045)

step: 900, train loss: 1.783(-0.049), val loss: 1.878(+0.018)

step: 1000, train loss: 1.780(-0.003), val loss: 1.779(-0.099)

step: 1100, train loss: 1.878(+0.098), val loss: 1.812(+0.033)

step: 1200, train loss: 1.760(-0.118), val loss: 1.772(-0.040)

step: 1300, train loss: 1.760(+0.000), val loss: 1.769(-0.003)

step: 1400, train loss: 1.853(+0.093), val loss: 1.746(-0.024)

step: 1500, train loss: 1.796(-0.057), val loss: 1.842(+0.096)

step: 1600, train loss: 1.759(-0.036), val loss: 1.803(-0.038)

step: 1700, train loss: 1.741(-0.018), val loss: 1.786(-0.017)

step: 1800, train loss: 1.749(+0.008), val loss: 1.782(-0.005)

step: 1900, train loss: 1.831(+0.082), val loss: 1.840(+0.058)

Total script runtime: 344.02 seconds

Starting script iteration 1 at: 2023-11-18 18:08:20

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

Starting script iteration 1 at: 2023-11-18 18:16:36

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.525(+0.000), val loss: 10.527(+0.000)

Starting script iteration 1 at: 2023-11-18 18:18:31

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.528(+0.000), val loss: 10.526(+0.000)

Starting script iteration 1 at: 2023-11-18 18:20:12

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.529(+0.000), val loss: 10.532(+0.000)

Starting script iteration 1 at: 2023-11-18 18:23:28

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.469(+0.000), val loss: 10.468(+0.000)

Starting script iteration 1 at: 2023-11-18 18:36:56

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.446(+0.000), val loss: 10.445(+0.000)

Starting script iteration 1 at: 2023-11-18 18:39:27

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.429(+0.000), val loss: 10.427(+0.000)

Starting script iteration 1 at: 2023-11-18 18:47:39

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.477(+0.000), val loss: 10.473(+0.000)

Starting script iteration 1 at: 2023-11-18 18:48:26

Block Size: 32, Batch Size: 128

Number of Heads: 1, Number of Layers: 1

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.476(+0.000), val loss: 10.474(+0.000)

step: 100, train loss: 2.406(-8.070), val loss: 2.393(-8.081)

step: 200, train loss: 2.377(-0.029), val loss: 2.313(-0.080)

step: 300, train loss: 2.278(-0.099), val loss: 2.354(+0.041)

step: 400, train loss: 2.325(+0.047), val loss: 2.316(-0.039)

step: 500, train loss: 2.208(-0.117), val loss: 2.277(-0.039)

step: 600, train loss: 2.257(+0.049), val loss: 2.240(-0.037)

step: 700, train loss: 2.203(-0.054), val loss: 2.198(-0.042)

step: 800, train loss: 2.074(-0.129), val loss: 2.102(-0.096)

step: 900, train loss: 2.158(+0.084), val loss: 2.108(+0.006)

step: 1000, train loss: 2.037(-0.121), val loss: 2.090(-0.018)

step: 1100, train loss: 2.076(+0.039), val loss: 2.112(+0.022)

Starting script iteration 1 at: 2023-11-18 18:52:45

Block Size: 32, Batch Size: 128

Number of Heads: 4, Number of Layers: 4

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.425(+0.000), val loss: 10.429(+0.000)

step: 100, train loss: 2.416(-8.009), val loss: 2.409(-8.020)

step: 200, train loss: 2.174(-0.243), val loss: 2.234(-0.175)

step: 300, train loss: 2.099(-0.074), val loss: 2.131(-0.103)

step: 400, train loss: 2.043(-0.056), val loss: 2.040(-0.091)

step: 500, train loss: 1.949(-0.095), val loss: 1.945(-0.094)

step: 600, train loss: 1.917(-0.031), val loss: 1.887(-0.058)

step: 700, train loss: 1.865(-0.053), val loss: 1.864(-0.023)

step: 800, train loss: 1.841(-0.023), val loss: 1.958(+0.094)

step: 900, train loss: 1.813(-0.028), val loss: 1.852(-0.106)

step: 1000, train loss: 1.801(-0.012), val loss: 1.794(-0.058)

step: 1100, train loss: 1.794(-0.008), val loss: 1.788(-0.006)

step: 1200, train loss: 1.777(-0.017), val loss: 1.751(-0.037)

step: 1300, train loss: 1.755(-0.022), val loss: 1.783(+0.031)

step: 1400, train loss: 1.773(+0.018), val loss: 1.727(-0.055)

step: 1500, train loss: 1.668(-0.105), val loss: 1.741(+0.014)

step: 1600, train loss: 1.739(+0.071), val loss: 1.707(-0.034)

step: 1700, train loss: 1.683(-0.056), val loss: 1.732(+0.025)

step: 1800, train loss: 1.659(-0.023), val loss: 1.697(-0.035)

step: 1900, train loss: 1.689(+0.030), val loss: 1.693(-0.003)

Total script runtime: 531.05 seconds

Starting script iteration 2 at: 2023-11-18 19:01:36

Block Size: 32, Batch Size: 128

Number of Heads: 4, Number of Layers: 4

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.694(+0.000), val loss: 1.666(+0.000)

step: 100, train loss: 1.652(-0.042), val loss: 1.593(-0.073)

step: 200, train loss: 1.756(+0.104), val loss: 1.672(+0.079)

step: 300, train loss: 1.632(-0.124), val loss: 1.598(-0.074)

step: 400, train loss: 1.706(+0.074), val loss: 1.622(+0.024)

step: 500, train loss: 1.642(-0.064), val loss: 1.653(+0.031)

step: 600, train loss: 1.600(-0.042), val loss: 1.636(-0.017)

step: 700, train loss: 1.627(+0.027), val loss: 1.605(-0.031)

step: 800, train loss: 1.628(+0.001), val loss: 1.619(+0.014)

step: 900, train loss: 1.649(+0.021), val loss: 1.589(-0.030)

step: 1000, train loss: 1.586(-0.063), val loss: 1.559(-0.031)

step: 1100, train loss: 1.574(-0.012), val loss: 1.633(+0.074)

step: 1200, train loss: 1.555(-0.019), val loss: 1.583(-0.049)

step: 1300, train loss: 1.576(+0.021), val loss: 1.561(-0.022)

step: 1400, train loss: 1.565(-0.011), val loss: 1.571(+0.011)

step: 1500, train loss: 1.588(+0.024), val loss: 1.499(-0.072)

step: 1600, train loss: 1.575(-0.014), val loss: 1.554(+0.054)

step: 1700, train loss: 1.512(-0.063), val loss: 1.529(-0.025)

step: 1800, train loss: 1.512(+0.000), val loss: 1.548(+0.018)

step: 1900, train loss: 1.548(+0.036), val loss: 1.610(+0.063)

Total script runtime: 532.34 seconds

Starting script iteration 3 at: 2023-11-18 19:10:28

Block Size: 32, Batch Size: 128

Number of Heads: 4, Number of Layers: 4

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.566(+0.000), val loss: 1.483(+0.000)

step: 100, train loss: 1.496(-0.070), val loss: 1.530(+0.047)

step: 200, train loss: 1.507(+0.011), val loss: 1.567(+0.037)

step: 300, train loss: 1.480(-0.027), val loss: 1.522(-0.045)

step: 400, train loss: 1.483(+0.003), val loss: 1.478(-0.043)

step: 500, train loss: 1.529(+0.047), val loss: 1.554(+0.076)

step: 600, train loss: 1.503(-0.026), val loss: 1.559(+0.005)

step: 700, train loss: 1.549(+0.046), val loss: 1.530(-0.030)

step: 800, train loss: 1.503(-0.046), val loss: 1.488(-0.041)

step: 900, train loss: 1.528(+0.025), val loss: 1.493(+0.005)

step: 1000, train loss: 1.583(+0.055), val loss: 1.560(+0.067)

step: 1100, train loss: 1.487(-0.096), val loss: 1.449(-0.112)

step: 1200, train loss: 1.551(+0.064), val loss: 1.537(+0.088)

step: 1300, train loss: 1.529(-0.022), val loss: 1.514(-0.023)

step: 1400, train loss: 1.471(-0.058), val loss: 1.544(+0.030)

step: 1500, train loss: 1.453(-0.018), val loss: 1.494(-0.050)

step: 1600, train loss: 1.472(+0.019), val loss: 1.471(-0.022)

step: 1700, train loss: 1.484(+0.011), val loss: 1.534(+0.063)

step: 1800, train loss: 1.492(+0.009), val loss: 1.458(-0.076)

step: 1900, train loss: 1.477(-0.015), val loss: 1.500(+0.042)

Total script runtime: 527.55 seconds

Starting script iteration 4 at: 2023-11-18 19:19:16

Block Size: 32, Batch Size: 128

Number of Heads: 4, Number of Layers: 4

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.526(+0.000), val loss: 1.455(+0.000)

step: 100, train loss: 1.510(-0.016), val loss: 1.488(+0.033)

step: 200, train loss: 1.578(+0.069), val loss: 1.496(+0.008)

step: 300, train loss: 1.437(-0.141), val loss: 1.431(-0.065)

step: 400, train loss: 1.488(+0.051), val loss: 1.488(+0.058)

step: 500, train loss: 1.468(-0.020), val loss: 1.419(-0.070)

step: 600, train loss: 1.421(-0.047), val loss: 1.504(+0.085)

step: 700, train loss: 1.509(+0.088), val loss: 1.552(+0.049)

step: 800, train loss: 1.558(+0.050), val loss: 1.474(-0.078)

step: 900, train loss: 1.502(-0.056), val loss: 1.471(-0.003)

step: 1000, train loss: 1.468(-0.034), val loss: 1.445(-0.026)

step: 1100, train loss: 1.461(-0.008), val loss: 1.461(+0.015)

step: 1200, train loss: 1.428(-0.033), val loss: 1.472(+0.012)

step: 1300, train loss: 1.420(-0.007), val loss: 1.484(+0.012)

step: 1400, train loss: 1.465(+0.044), val loss: 1.467(-0.017)

step: 1500, train loss: 1.452(-0.012), val loss: 1.492(+0.025)

step: 1600, train loss: 1.507(+0.055), val loss: 1.466(-0.026)

step: 1700, train loss: 1.414(-0.094), val loss: 1.426(-0.041)

step: 1800, train loss: 1.547(+0.133), val loss: 1.443(+0.017)

step: 1900, train loss: 1.450(-0.097), val loss: 1.463(+0.020)

Total script runtime: 532.66 seconds

Starting script iteration 5 at: 2023-11-18 19:28:09

Block Size: 32, Batch Size: 128

Number of Heads: 4, Number of Layers: 4

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.501(+0.000), val loss: 1.482(+0.000)

step: 100, train loss: 1.454(-0.047), val loss: 1.463(-0.019)

step: 200, train loss: 1.451(-0.003), val loss: 1.421(-0.042)

step: 300, train loss: 1.425(-0.026), val loss: 1.559(+0.137)

step: 400, train loss: 1.401(-0.024), val loss: 1.525(-0.034)

step: 500, train loss: 1.472(+0.071), val loss: 1.417(-0.108)

step: 600, train loss: 1.474(+0.002), val loss: 1.458(+0.041)

step: 700, train loss: 1.410(-0.064), val loss: 1.474(+0.016)

step: 800, train loss: 1.399(-0.011), val loss: 1.445(-0.029)

step: 900, train loss: 1.432(+0.033), val loss: 1.420(-0.025)

step: 1000, train loss: 1.417(-0.015), val loss: 1.404(-0.017)

step: 1100, train loss: 1.499(+0.082), val loss: 1.443(+0.039)

step: 1200, train loss: 1.409(-0.090), val loss: 1.437(-0.006)

step: 1300, train loss: 1.468(+0.059), val loss: 1.378(-0.059)

step: 1400, train loss: 1.437(-0.031), val loss: 1.462(+0.084)

step: 1500, train loss: 1.438(+0.001), val loss: 1.444(-0.018)

step: 1600, train loss: 1.469(+0.031), val loss: 1.387(-0.056)

step: 1700, train loss: 1.436(-0.033), val loss: 1.473(+0.086)

step: 1800, train loss: 1.391(-0.045), val loss: 1.423(-0.050)

step: 1900, train loss: 1.406(+0.015), val loss: 1.390(-0.033)

Total script runtime: 535.43 seconds

Starting script iteration 1 at: 2023-11-18 19:53:50

Block Size: 32, Batch Size: 128

Number of Heads: 8, Number of Layers: 8

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.412(+0.000), val loss: 10.402(+0.000)

step: 100, train loss: 2.422(-7.990), val loss: 2.426(-7.976)

step: 200, train loss: 2.237(-0.185), val loss: 2.264(-0.162)

step: 300, train loss: 2.065(-0.172), val loss: 2.051(-0.213)

step: 400, train loss: 2.045(-0.020), val loss: 2.047(-0.004)

step: 500, train loss: 1.937(-0.108), val loss: 1.950(-0.097)

step: 600, train loss: 1.875(-0.062), val loss: 1.883(-0.067)

step: 700, train loss: 1.859(-0.016), val loss: 1.862(-0.020)

step: 800, train loss: 1.842(-0.017), val loss: 1.809(-0.053)

step: 900, train loss: 1.784(-0.058), val loss: 1.770(-0.039)

step: 1000, train loss: 1.698(-0.086), val loss: 1.717(-0.052)

step: 1100, train loss: 1.680(-0.018), val loss: 1.723(+0.005)

step: 1200, train loss: 1.709(+0.028), val loss: 1.695(-0.027)

step: 1300, train loss: 1.653(-0.055), val loss: 1.695(-0.000)

step: 1400, train loss: 1.734(+0.081), val loss: 1.698(+0.003)

step: 1500, train loss: 1.658(-0.076), val loss: 1.645(-0.053)

step: 1600, train loss: 1.654(-0.005), val loss: 1.668(+0.023)

step: 1700, train loss: 1.620(-0.034), val loss: 1.673(+0.005)

step: 1800, train loss: 1.649(+0.029), val loss: 1.608(-0.065)

step: 1900, train loss: 1.529(-0.120), val loss: 1.634(+0.026)

Total script runtime: 13.34 minutes

Starting script iteration 2 at: 2023-11-18 20:07:11

Block Size: 32, Batch Size: 128

Number of Heads: 8, Number of Layers: 8

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 1.582(+0.000), val loss: 1.608(+0.000)

step: 100, train loss: 1.563(-0.020), val loss: 1.550(-0.059)

step: 200, train loss: 1.565(+0.002), val loss: 1.586(+0.036)

step: 300, train loss: 1.677(+0.113), val loss: 1.574(-0.012)

Starting script iteration 1 at: 2023-11-18 20:10:21

Block Size: 64, Batch Size: 128

Number of Heads: 8, Number of Layers: 8

Max Iterations: 2000, Eval Iters: 100

Learning Rate: 0.0003

Embedding Size: 384, Dropout: 0.2

step: 0, train loss: 10.390(+0.000), val loss: 10.392(+0.000)

step: 100, train loss: 2.370(-8.020), val loss: 2.411(-7.981)

step: 200, train loss: 2.198(-0.172), val loss: 2.235(-0.177)

step: 300, train loss: 2.080(-0.118), val loss: 2.102(-0.133)

step: 400, train loss: 2.032(-0.048), val loss: 1.985(-0.117)

step: 500, train loss: 1.888(-0.144), val loss: 1.898(-0.087)

step: 600, train loss: 1.913(+0.025), val loss: 1.900(+0.002)

step: 700, train loss: 1.727(-0.186), val loss: 1.797(-0.102)

step: 800, train loss: 1.799(+0.073), val loss: 1.727(-0.070)

step: 900, train loss: 1.662(-0.137), val loss: 1.704(-0.023)

step: 1000, train loss: 1.659(-0.003), val loss: 1.671(-0.033)

step: 1100, train loss: 1.649(-0.010), val loss: 1.601(-0.070)

step: 1200, train loss: 1.630(-0.019), val loss: 1.585(-0.016)

step: 1300, train loss: 1.553(-0.077), val loss: 1.554(-0.031)

step: 1400, train loss: 1.629(+0.076), val loss: 1.619(+0.065)

step: 1500, train loss: 1.523(-0.106), val loss: 1.536(-0.084)

step: 1600, train loss: 1.513(-0.010), val loss: 1.574(+0.038)

step: 1700, train loss: 1.550(+0.037), val loss: 1.545(-0.029)

step: 1800, train loss: 1.527(-0.023), val loss: 1.514(-0.031)

step: 1900, train loss: 1.479(-0.049), val loss: 1.502(-0.012)

Total script runtime: 26.27 minutes
